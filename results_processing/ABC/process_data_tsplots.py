import string
import time
import os
import argparse
from pathlib import Path
import json
import matplotlib.pyplot as plt
import seaborn as sns
from distutils import dir_util
from pprint import pprint
import pickle
import pandas as pd
import random
import pprint
import numpy as np
import datetime

# BayesCMD packages
from bayescmd.results_handling import kde_plot
from bayescmd.results_handling import scatter_dist_plot
from bayescmd.results_handling import data_import
from bayescmd.results_handling import plot_repeated_outputs
from bayescmd.results_handling import histogram_plot
from bayescmd.results_handling import data_merge_by_batch
from bayescmd.abc import import_actual_data
from bayescmd.abc import priors_creator
from bayescmd.abc import get_distance
from bayescmd.abc import inputParse
from bayescmd.bcmdModel import ModelBCMD
from subprocess import TimeoutExpired, CalledProcessError  # noqa

# Google BigQuery
from google.cloud import bigquery
get_ipython().run_line_magic('load_ext', 'google.cloud.bigquery')


client = bigquery.Client.from_service_account_json(
    "../gcloud/hypothermia-auth.json"
)


def generate_histogram_query(project, neonate, n_bins, distance):
    histogram_query = """
    SELECT
      MIN(data.{distance}) AS min,
      MAX(data.{distance}) AS max,
      COUNT(data.{distance}) AS num,
      INTEGER((data.{distance}-value.min)/(value.max-value.min)*{n_bins}) AS group_
    FROM
      [{project}:neo_desat.{neonate}_gradient] data
    CROSS JOIN (
      SELECT
        MAX({distance}) AS max,
        MIN({distance}) AS min
      FROM
        [{project}:neo_desat.{neonate}_gradient]) value
    GROUP BY
      group_
    ORDER BY
      group_
    """.format(neonate=neonate, n_bins=n_bins, distance=distance, project=project)
    return histogram_query


# In[4]:


def generate_posterior_query(project, neonate, distance, parameters, limit=50000):
    unpacked_params = ",\n".join(parameters)
    posterior_query = """
SELECT
    {unpacked_params},
    {distance},
    idx
FROM
  `{project}.neo_desat.{neonate}_gradient`
ORDER BY
  {distance} ASC
LIMIT
  {limit}
    """.format(project=project, neonate=neonate, unpacked_params=unpacked_params, distance=distance, limit=limit)
    return posterior_query


def load_configuration(neonate, verbose=False):
    current_file = Path(os.path.abspath(''))
    config_file = os.path.join(current_file.parents[1],
                               'config_files',
                               'abc',
                               'neo_config.json'
                               )

    with open(config_file, 'r') as conf_f:
        conf = json.load(conf_f)

    params = conf['priors']

    input_path = os.path.join(current_file.parents[1],
                              'data',
                              'formatted_data',
                              '{}_formatted.csv'.format(neonate))

    d0 = import_actual_data(input_path)

    targets = conf['targets']
    model_name = conf['model_name']
    inputs = conf['inputs']

    config = {
        "model_name": model_name,
        "targets": targets,
        "inputs": inputs,
        "parameters": params,
        "input_path": input_path,
        "zero_flag": conf['zero_flag'],
    }

    if verbose:
        pprint(config)

    return config, d0


configuration = {}

neonates = ['neo007', 'neo021']


class Timer(object):
    def __init__(self, name=None):
        self.name = name

    def __enter__(self):
        self.tstart = time.time()

    def __exit__(self, type, value, traceback):
        if self.name:
            print('[%s]' % self.name,)
        print('Elapsed: %s' % (time.time() - self.tstart))


def run_model(model):
    """Run a BCMD Model.

    Parameters
    ----------
    model : :obj:`bayescmd.bcmdModel.ModelBCMD`
        An initialised instance of a ModelBCMD class.

    Returns
    -------
    output : :obj:`dict`
        Dictionary of parsed model output.

    """

    model.create_initialised_input()

    model.run_from_buffer()

    output = model.output_parse()
    return output


def get_output(model_name,
               p,
               times,
               input_data,
               d0,
               targets,
               distance='euclidean',
               zero_flag=None):
    """Generate model output and distances.

    Parameters
    ----------
    model_name : :obj:`str`
        Name of model
    p : :obj:`dict`
        Dict of form {'parameter': value} for which posteriors are being
        investigated.
    times : :obj:`list` of :obj:`float`
        List of times at which the data was collected.
    input_data : :obj:`dict`
        Dictionary of input data as generated by :obj:`abc.inputParse`.
    d0 : :obj:`dict`
        Dictionary of real data, as generated by :obj:`abc.import_actual_data`.
    targets : :obj:`list` of :obj:`str`
        List of model outputs against which the model is being optimised.
    distance : :obj:`str`
        Distance measure. One of 'euclidean', 'manhattan', 'MAE', 'MSE'.
    zero_flag : dict
        Dictionary of form target(:obj:`str`): bool, where bool indicates
        whether to zero that target.

        Note: zero_flag keys should match targets list.

    Returns
    -------
    :obj:`tuple`
        A tuple of (p, model output data).

    """
    _model = ModelBCMD(
        model_name, inputs=input_data, params=p, times=times, outputs=targets, suppress=True)

    output = run_model(_model)

    dist = get_distance(
        d0,
        output,
        targets,
        distance=distance.split("_")[-1],
        zero_flag=zero_flag)

    try:
        for k, v in dist.items():
            p[k] = v
    except AttributeError as e:
        print("Error in finding distance.\n dist is {}:".format(dist))
        pprint.pprint(p)
        pprint.pprint(output)

        raise e

    if zero_flag:
        for k, boolean in zero_flag.items():
            if boolean:
                output[k] = [x - output[k][0] for x in output[k]]
    return p, output


# In[10]:


def get_repeated_outputs(df,
                         model_name,
                         parameters,
                         input_path,
                         inputs,
                         targets,
                         n_repeats,
                         zero_flag,
                         neonate,
                         tolerance=None,
                         limit=None,
                         frac=None,
                         openopt_path=None,
                         offset=None,
                         distance='euclidean'
                         ):
    """Generate model output and distances multiple times.

    Parameters
    ----------
    model_name : :obj:`str`
        Names of model. Should match the modeldef file for model being generated
        i.e. model_name of 'model`' should have a modeldef file
        'model1.modeldef'.
    parameters : :obj:`dict` of :obj:`str`: :obj:`tuple`
        Dict of model parameters to compare, with value tuple of the prior max
        and min.
    input_path : :obj:`str`
        Path to the true data file
    inputs : :obj:`list` of :obj:`str`
        List of model inputs.
    targets : :obj:`list` of :obj:`str`
        List of model outputs against which the model is being o config = configuration[NEONATE]['bayescmd_config']ptimised.
    n_repeats : :obj: `int` config = configuration[NEONATE]['bayescmd_config']
        Number of times to generate output data config = configuration[NEONATE]['bayescmd_config']
    frac : :obj:`float` config = configuration[NEONATE]['bayescmd_config']
        Fraction of results to consider. Should be given as a pe config = configuration[NEONATE]['bayescmd_config']rcentage i.e.
        1=1%, 0.1=0.1% config = configuration[NEONATE]['bayescmd_config']
    zero_flag : dict config = configuration[NEONATE]['bayescmd_config']
        Dictionary of form target(:obj:`str`): bool, where bool  config = configuration[NEONATE]['bayescmd_config']indicates
        whether to zero that target. config = configuration[NEONATE]['bayescmd_config']

        Note: zero_flag keys should match targets list.
    openopt_path : :obj:`str` or :obj:`None`
        Path to the openopt data file if it exists. Default is None.
    offset : :obj:`dict`
        Dictionary of offset parameters if they are needed
    distance : :obj:`str`, optional
        Distance measure. One of 'euclidean', 'manhattan', 'MAE', 'MSE'.

    Returns
    -------
    fig : :obj:`matplotlib.figure`
        Figure containing all axes.

    """
    p_names = list(parameters.keys())
    sorted_df = df.sort_values(by=distance)

    if tolerance:
        accepted_limit = sum(df[distance].values < tolerance)
    elif limit:
        accepted_limit = limit
    elif frac:
        accepted_limit = frac_calculator(sorted_df, frac)
    else:
        raise ValueError('No limit or fraction given.')

    df_list = []
    if n_repeats > accepted_limit:
        print(
            "Setting number of repeats to quarter of the posterior size\n",
            file=sys.stderr)
        n_repeats = int(accepted_limit / 4)
    d0 = import_actual_data(input_path)
    input_data = inputParse(d0, inputs)

    true_data = pd.read_csv(input_path)
    times = true_data['t'].values

    if openopt_path:
        openopt_data = pd.read_csv(openopt_path)

    if n_repeats > accepted_limit:
        raise ValueError(
            "Number of requested model runs greater than posterior size:"
            "\n\tPosterior Size: {}\n\tNumber of runs: {}".format(
                accepted_limit, n_repeats))

    rand_selection = list(range(accepted_limit))
    random.shuffle(rand_selection)

    outputs_list = []

    posteriors = sorted_df.iloc[:accepted_limit][p_names].values
    select_idx = 0
    with Timer("Running repeat outputs"):
        while len(outputs_list) < n_repeats:
            try:
                idx = rand_selection.pop()
                p = dict(zip(p_names, posteriors[idx]))
                if offset:
                    p = {**p, **offset}
                output = get_output(
                    model_name,
                    p,
                    times,
                    input_data,
                    d0,
                    targets,
                    distance=distance,
                    zero_flag=zero_flag)
                outputs_list.append(output)
                print("Sample {}, idx:{}".format(len(outputs_list), idx))

            except (TimeoutError, TimeoutExpired) as e:
                print("Timed out for Sample {}, idx:{}".format(
                    len(outputs_list), idx))
                pprint.pprint(p)
                rand_selection.insert(0, idx)
            except (CalledProcessError) as e:
                print("CalledProcessError for Sample {}, idx:{}".format(
                    len(outputs_list), idx))
                pprint.pprint(p)
                rand_selection.insert(0, idx)

    d = {"Errors": {}, "Outputs": {}}
    d['Errors']['Average'] = np.nanmean(
        [o[0]['TOTAL'] for o in outputs_list])
    for target in targets:
        d['Errors'][target] = np.nanmean(
            [o[0][target] for o in outputs_list])
        d['Outputs'][target] = [o[1][target] for o in outputs_list]

    for ii, target in enumerate(targets):
        x = [j for j in times for n in range(len(d['Outputs'][target]))]
        with Timer('Transposing {}'.format(target)):
            y = np.array(d['Outputs'][target]).transpose()
            y = y.ravel()
        with Timer("Crafting DataFrame for {}".format(target)):
            model_name_col = [neonate]*len(x)
            target_col = [target]*len(x)
            df1 = pd.DataFrame(
                {"Time": x, "Posterior": y, "Neonate": model_name_col, "Output": target_col})
        with Timer("Appending dataframe for {}".format(target)):
            df_list.append(df1.copy())
            del df1
    return pd.concat(df_list), true_data

# In[ ]:


labels = {"t": "Time (sec)",
          "SaO2sup": "SaO2 (%)",
          "P_a": "ABP (mmHg)",
          "PaCO2": "PaCO$_2$ (mmHg)",
          "temp": "Temperature ($^{\circ}$C)",
          "TOI": "TOI (%)",
          "HbT": "$\Delta$HbT $(\mu M)$",
          "Hbdiff": "$\Delta$HbD $(\mu M)$",
          "CCO": "$\Delta$CCO $(\mu M)$"
          }
LIM = 4000
neonates = ["neo007", "neo021"]


signals = ['CCO', 'HbT', 'Hbdiff']

for SIGNAL in [''] + signals:
    print("Working on {} ".format(SIGNAL if SIGNAL != '' else "TOTAL"))
    for NEONATE in neonates:

        print("Working on {} ".format(NEONATE))

        configuration[NEONATE] = {}
        config, d0 = load_configuration(NEONATE)
        configuration[NEONATE]['bayescmd_config'] = config
        configuration[NEONATE]['original_data'] = d0
        if SIGNAL != '':
            distance = SIGNAL + "_NRMSE"
        else:
            distance = "NRMSE"
        configuration[NEONATE]['histogram_query'] = generate_histogram_query('hypothermia-bayescmd',
                                                                             NEONATE,
                                                                             100,
                                                                             distance)

        configuration[NEONATE]['posterior_query'] = generate_posterior_query('hypothermia-bayescmd',
                                                                             NEONATE,
                                                                             distance,
                                                                             list(
                                                                                 configuration[NEONATE]['bayescmd_config']['parameters'].keys()),
                                                                             limit=LIM)
        # Set config and create figure path

        figPath = "/home/buck06191/Dropbox/phd/desat_neonate/ABC/Figures/{}_gradient/{}".format(
            NEONATE, distance)
        dir_util.mkpath(figPath)

        # Get posterior
        print("\tRunning SQL query")
        df_post = client.query(
            configuration[NEONATE]['posterior_query']).to_dataframe()

        # Plot posterior predictive
        config["offset"] = {}
        print("\tGetting Posterior Predictive")

        with Timer("Getting outputs"):

            df_dict = {}
            df_list, true_data = get_repeated_outputs(df_post, n_repeats=LIM/2, limit=LIM,
                                                      distance=distance, neonate=NEONATE, **config)
            df_dict[NEONATE] = df_list

            ylabel_dict = labels
            all_outputs = pd.concat(list(df_dict.values()))
        with Timer("Plotting line plot"):
            g = sns.FacetGrid(all_outputs, row='Output',
                              hue='Neonate', height=2.5, aspect=2, sharey=False)

            for ii, ax in enumerate(g.axes.flatten()):
                ax.plot(true_data['t'], true_data[signals[ii]], 'k', '-')

            g = (g.map_dataframe(sns.lineplot, x='Time', y='Posterior',
                                 estimator=np.median, ci=95)).add_legend()
            plt.setp(g._legend.get_title(), fontsize=12)
            plt.setp(g._legend.get_texts(), fontsize=11)
            g = g.set_titles('')
            g = g.set_xlabels('Time (sec)', fontsize=12)

            for ii, ax in enumerate(g.axes.flatten()):
                ax.set_ylabel(ylabel_dict[signals[ii]], fontsize=12)

                nticks = 5
                ax.set_xticklabels(ax.get_xticklabels(), fontsize=11)
                ax.autoscale()
                y_min, y_max = ax.get_ylim()
                ax.set_yticks(np.linspace(y_min, y_max, nticks))
                ax.set_yticklabels(["{:.2g}".format(y)
                                    for y in np.linspace(y_min, y_max, nticks)], fontdict={'fontsize': 11})
                ax.set_title(
                    string.ascii_lowercase[ii] + ")", fontsize=10, loc='left')
        g.fig.align_ylabels()
        g.fig.subplots_adjust(hspace=0.15)
        g.savefig(figPath+'/{}_postpred.png'.format(NEONATE),
                  dpi=250, bbox_inches='tight', transparent=True)
